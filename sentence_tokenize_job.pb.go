// Code generated by protoc-gen-go. DO NOT EDIT.
// source: sentence_tokenize_job.proto

/*
Package sentence_tokenize_job is a generated protocol buffer package.

It is generated from these files:
	sentence_tokenize_job.proto

It has these top-level messages:
	TokenizeRequest
	TokenizeReply
*/
package sentence_tokenize_job

import proto "github.com/golang/protobuf/proto"
import fmt "fmt"
import math "math"

import (
	context "golang.org/x/net/context"
	grpc "google.golang.org/grpc"
)

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// This is a compile-time assertion to ensure that this generated file
// is compatible with the proto package it is being compiled against.
// A compilation error at this line likely means your copy of the
// proto package needs to be updated.
const _ = proto.ProtoPackageIsVersion2 // please upgrade the proto package

type TokenizeRequest struct {
	Language  string `protobuf:"bytes,1,opt,name=language" json:"language,omitempty"`
	Ids       string `protobuf:"bytes,2,opt,name=ids" json:"ids,omitempty"`
	Paragraph string `protobuf:"bytes,3,opt,name=paragraph" json:"paragraph,omitempty"`
}

func (m *TokenizeRequest) Reset()                    { *m = TokenizeRequest{} }
func (m *TokenizeRequest) String() string            { return proto.CompactTextString(m) }
func (*TokenizeRequest) ProtoMessage()               {}
func (*TokenizeRequest) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{0} }

func (m *TokenizeRequest) GetLanguage() string {
	if m != nil {
		return m.Language
	}
	return ""
}

func (m *TokenizeRequest) GetIds() string {
	if m != nil {
		return m.Ids
	}
	return ""
}

func (m *TokenizeRequest) GetParagraph() string {
	if m != nil {
		return m.Paragraph
	}
	return ""
}

type TokenizeReply struct {
	Ids       string   `protobuf:"bytes,1,opt,name=ids" json:"ids,omitempty"`
	Sentences []string `protobuf:"bytes,2,rep,name=sentences" json:"sentences,omitempty"`
}

func (m *TokenizeReply) Reset()                    { *m = TokenizeReply{} }
func (m *TokenizeReply) String() string            { return proto.CompactTextString(m) }
func (*TokenizeReply) ProtoMessage()               {}
func (*TokenizeReply) Descriptor() ([]byte, []int) { return fileDescriptor0, []int{1} }

func (m *TokenizeReply) GetIds() string {
	if m != nil {
		return m.Ids
	}
	return ""
}

func (m *TokenizeReply) GetSentences() []string {
	if m != nil {
		return m.Sentences
	}
	return nil
}

func init() {
	proto.RegisterType((*TokenizeRequest)(nil), "TokenizeRequest")
	proto.RegisterType((*TokenizeReply)(nil), "TokenizeReply")
}

// Reference imports to suppress errors if they are not otherwise used.
var _ context.Context
var _ grpc.ClientConn

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
const _ = grpc.SupportPackageIsVersion4

// Client API for TokenizeJob service

type TokenizeJobClient interface {
	TokenizeStream(ctx context.Context, opts ...grpc.CallOption) (TokenizeJob_TokenizeStreamClient, error)
}

type tokenizeJobClient struct {
	cc *grpc.ClientConn
}

func NewTokenizeJobClient(cc *grpc.ClientConn) TokenizeJobClient {
	return &tokenizeJobClient{cc}
}

func (c *tokenizeJobClient) TokenizeStream(ctx context.Context, opts ...grpc.CallOption) (TokenizeJob_TokenizeStreamClient, error) {
	stream, err := grpc.NewClientStream(ctx, &_TokenizeJob_serviceDesc.Streams[0], c.cc, "/TokenizeJob/tokenize_stream", opts...)
	if err != nil {
		return nil, err
	}
	x := &tokenizeJobTokenizeStreamClient{stream}
	return x, nil
}

type TokenizeJob_TokenizeStreamClient interface {
	Send(*TokenizeRequest) error
	Recv() (*TokenizeReply, error)
	grpc.ClientStream
}

type tokenizeJobTokenizeStreamClient struct {
	grpc.ClientStream
}

func (x *tokenizeJobTokenizeStreamClient) Send(m *TokenizeRequest) error {
	return x.ClientStream.SendMsg(m)
}

func (x *tokenizeJobTokenizeStreamClient) Recv() (*TokenizeReply, error) {
	m := new(TokenizeReply)
	if err := x.ClientStream.RecvMsg(m); err != nil {
		return nil, err
	}
	return m, nil
}

// Server API for TokenizeJob service

type TokenizeJobServer interface {
	TokenizeStream(TokenizeJob_TokenizeStreamServer) error
}

func RegisterTokenizeJobServer(s *grpc.Server, srv TokenizeJobServer) {
	s.RegisterService(&_TokenizeJob_serviceDesc, srv)
}

func _TokenizeJob_TokenizeStream_Handler(srv interface{}, stream grpc.ServerStream) error {
	return srv.(TokenizeJobServer).TokenizeStream(&tokenizeJobTokenizeStreamServer{stream})
}

type TokenizeJob_TokenizeStreamServer interface {
	Send(*TokenizeReply) error
	Recv() (*TokenizeRequest, error)
	grpc.ServerStream
}

type tokenizeJobTokenizeStreamServer struct {
	grpc.ServerStream
}

func (x *tokenizeJobTokenizeStreamServer) Send(m *TokenizeReply) error {
	return x.ServerStream.SendMsg(m)
}

func (x *tokenizeJobTokenizeStreamServer) Recv() (*TokenizeRequest, error) {
	m := new(TokenizeRequest)
	if err := x.ServerStream.RecvMsg(m); err != nil {
		return nil, err
	}
	return m, nil
}

var _TokenizeJob_serviceDesc = grpc.ServiceDesc{
	ServiceName: "TokenizeJob",
	HandlerType: (*TokenizeJobServer)(nil),
	Methods:     []grpc.MethodDesc{},
	Streams: []grpc.StreamDesc{
		{
			StreamName:    "tokenize_stream",
			Handler:       _TokenizeJob_TokenizeStream_Handler,
			ServerStreams: true,
			ClientStreams: true,
		},
	},
	Metadata: "sentence_tokenize_job.proto",
}

func init() { proto.RegisterFile("sentence_tokenize_job.proto", fileDescriptor0) }

var fileDescriptor0 = []byte{
	// 186 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0xe2, 0x92, 0x2e, 0x4e, 0xcd, 0x2b,
	0x49, 0xcd, 0x4b, 0x4e, 0x8d, 0x2f, 0xc9, 0xcf, 0x4e, 0xcd, 0xcb, 0xac, 0x4a, 0x8d, 0xcf, 0xca,
	0x4f, 0xd2, 0x2b, 0x28, 0xca, 0x2f, 0xc9, 0x57, 0x8a, 0xe5, 0xe2, 0x0f, 0x81, 0x8a, 0x06, 0xa5,
	0x16, 0x96, 0xa6, 0x16, 0x97, 0x08, 0x49, 0x71, 0x71, 0xe4, 0x24, 0xe6, 0xa5, 0x97, 0x26, 0xa6,
	0xa7, 0x4a, 0x30, 0x2a, 0x30, 0x6a, 0x70, 0x06, 0xc1, 0xf9, 0x42, 0x02, 0x5c, 0xcc, 0x99, 0x29,
	0xc5, 0x12, 0x4c, 0x60, 0x61, 0x10, 0x53, 0x48, 0x86, 0x8b, 0xb3, 0x20, 0xb1, 0x28, 0x31, 0xbd,
	0x28, 0xb1, 0x20, 0x43, 0x82, 0x19, 0x2c, 0x8e, 0x10, 0x50, 0xb2, 0xe7, 0xe2, 0x45, 0x18, 0x5f,
	0x90, 0x53, 0x09, 0x33, 0x80, 0x11, 0xc5, 0x00, 0x98, 0x03, 0x41, 0x06, 0x33, 0x83, 0x0c, 0x80,
	0x0b, 0x18, 0x79, 0x70, 0x71, 0xc3, 0x0c, 0xf0, 0xca, 0x4f, 0x12, 0xb2, 0xe4, 0xe2, 0x87, 0x7b,
	0xa2, 0xb8, 0xa4, 0x28, 0x35, 0x31, 0x57, 0x48, 0x40, 0x0f, 0xcd, 0x03, 0x52, 0x7c, 0x7a, 0x28,
	0x76, 0x2a, 0x31, 0x68, 0x30, 0x1a, 0x30, 0x26, 0xb1, 0x81, 0x3d, 0x6c, 0x0c, 0x08, 0x00, 0x00,
	0xff, 0xff, 0x62, 0x90, 0xb0, 0xe0, 0x0f, 0x01, 0x00, 0x00,
}
